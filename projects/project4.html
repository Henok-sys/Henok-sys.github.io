<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Gesture Control Evaluation</title>
  <link rel="stylesheet" href="../style.css"> <!-- Link to your CSS file -->
</head>
<body>

  <!-- Header Section -->
  <header>
    <nav>
      <a href="#home" class="home-button">Henok</a>
      <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="../hci.html">CS376: HCI</a></li>
        <li class="dropdown">
          <a href="../index.html#projects">HCI Projects</a>
          <ul class="dropdown-menu">
            <li><a href="project1.html">Ephs SmartWatching for Health</a></li>
            <li><a href="project2.html">Enhancing Usability in the Health Portal</a></li>
            <li><a href="project3.html">Running with Your Hands</a></li>
            <li><a href="project4.html">Gesture Control Evaluation</a></li>
            <li><a href="project5.html">HelpMeStudy Extension</a></li>
          </ul>
        </li>
        <li><a href="../index.html#contact">Contact</a></li>
      </ul>
    </nav>
  </header>

  <!-- Project 1 Section -->
  <section id="project-1" class="projects-section">
    <div class="project">
      <h3 class="project-title">Gesture Control Evaluation</h3>

      <p class="project-paragraph">
        Developing products goes beyond simply building features; it requires systematically evaluating the results to ensure the product meets user needs and expectations. For our gesture control implementation of temple run, we conducted an in-depth evaluation process to assess its functionality and user experience. Our evaluation included both qualitative and quantitative feedback mechanisms, providing a comprehensive understanding of how users interacted with the system. This dual approach allowed us to identify strengths and weaknesses, guiding improvements for possible future iterations.
      </p>
      <figure class="project-figure">
        <img src="../assets/tli.png" alt="Smartwatch data analysis" class="project-image">
        <figcaption class="image-caption"> NASA TLX form for Quantitative Feedback </figcaption>
      </figure>
      
      <p class="project-paragraph">
        For quantitative feedback, we employed a Likert-scale questionnaire based on the NASA Task Load Index (NASA-TLX). This tool measured user perceptions of workload, frustration, and mental effort during their interaction with our system. The structured format of the Likert scale provided numerical data that quantified the user experience, complementing the qualitative insights and offering a clearer picture of the system's usability. By combining these methods, we balanced subjective user narratives with objective metrics, strengthening the reliability of our findings.
      </p>
      
      <figure class="project-figure">
        <img src="../assets/evalForm.png" alt="Empathy map for smartwatch users" class="project-image">
        <figcaption class="image-caption"> Google Form for Qualitative Feedback </figcaption>
      </figure>
      <p class="project-paragraph">
        To gather qualitative feedback, we used Google Forms to collect open-ended responses from users. Participants shared their experiences using the gesture controls, focusing on ease of use, intuitiveness, and any areas of confusion or frustration. This approach resembled the needfinding process in that it captured insights directly from the users. However, the distinction lay in its specificity; while needfinding seeks to identify user requirements broadly, evaluation hones in on the actual performance of the implemented features, providing actionable insights.
      </p>

      <figure class="project-figure">
        <img src="../assets/evalResults.png" alt="Empathy map for smartwatch users" class="project-image">
        <figcaption class="image-caption"> Results for Keyboard and Gesture Controls </figcaption>
      </figure>

      <p class="project-paragraph">
        In addition to testing our own implementation, we evaluated other gesture control systems. This comparative analysis offered valuable perspective, allowing us to see both sides of user interactions: what worked well and what did not. For instance, certain frustrating features in competing systems, such as unresponsive gestures or inconsistent feedback, highlighted potential pitfalls that we might have overlooked without hands-on testing. This iterative process emphasized the importance of experiencing the product from the user's perspective to identify shortcomings that could hinder its effectiveness.
      </p>
      
      <p class="project-paragraph">
        Overall, our evaluation process underscored the vital role of testing and feedback in creating effective designs. By iterating based on user insights, we could refine our gesture controls to address user frustrations and enhance the overall experience. Evaluation served not only as a tool for measuring success but also as a guide for improvement. Moving forward, this practice will remain integral to our development process, ensuring that our designs evolve to meet user needs effectively.
      </p>

      <!-- Link to Medium Post -->
      <div class="medium-link">
        <a href="https://medium.com/@hf7/gesture-control-evaluation-1c5e055048dc" target="_blank">
          <div class="medium-content">
            <img src="../assets/Medium-Wordmark-Black.png" alt="Medium Icon" class="medium-icon">
            <span>Read the full desing document.</span>
          </div>
        </a>
      </div>
      
  </section>

  <!-- Footer Section -->
  <footer>
    <p>Â© 2024 Henok Misgina Fisseha</p>
  </footer>

</body>
</html>

